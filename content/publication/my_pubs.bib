
@article{cushing_neurodynamics_2018,
	title = {Neurodynamics and connectivity during facial fear perception: The role of threat exposure and signal congruity},
	volume = {8},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-018-20509-8},
	doi = {10.1038/s41598-018-20509-8},
	shorttitle = {Neurodynamics and connectivity during facial fear perception},
	number = {1},
	journaltitle = {Scientific Reports},
	author = {Cushing, Cody A. and Im, Hee Yeon and Adams, Reginald B. and Ward, Noreen and Albohn, Daniel N. and Steiner, Troy G. and Kveraga, Kestutis},
	urldate = {2018-12-19},
	date = {2018-12},
	langid = {english}
}

@incollection{albohn_social_2016,
	title = {Social Vision: At the Intersection of Vision and Person Perception},
	isbn = {978-0-12-800935-2},
	url = {https://linkinghub.elsevier.com/retrieve/pii/C20130186230},
	booktitle = {Neuroimaging Personality, Social Cognition, and Character},
	publisher = {Elsevier},
	author = {Albohn, Daniel N. and Adams, Reginald B.},
	editor = {Absher, {JR} and Cloutier, J},
	urldate = {2018-12-19},
	date = {2016},
	langid = {english},
	doi = {10.1016/C2013-0-18623-0}
}

@article{im_differential_2017,
	title = {Differential hemispheric and visual stream contributions to ensemble coding of crowd emotion},
	volume = {1},
	issn = {2397-3374},
	url = {http://www.nature.com/articles/s41562-017-0225-z},
	doi = {10.1038/s41562-017-0225-z},
	pages = {828--842},
	number = {11},
	journaltitle = {Nature Human Behaviour},
	author = {Im, Hee Yeon and Albohn, Daniel N. and Steiner, Troy G. and Cushing, Cody A. and Adams, Reginald B. and Kveraga, Kestutis},
	urldate = {2018-12-19},
	date = {2017-11},
	langid = {english}
}

@article{adams_what_2016,
	title = {What Facial Appearance Reveals Over Time: When Perceived Expressions in Neutral Faces Reveal Stable Emotion Dispositions},
	volume = {7},
	issn = {1664-1078},
	url = {http://journal.frontiersin.org/Article/10.3389/fpsyg.2016.00986/abstract},
	doi = {10.3389/fpsyg.2016.00986},
	shorttitle = {What Facial Appearance Reveals Over Time},
	abstract = {It might seem a reasonable assumption that when we are not actively using our faces to express ourselves (i.e., when we display nonexpressive, or neutral faces), those around us will not be able to read our emotions. Herein, using a variety of expression-related ratings, we examined whether age-related changes in the face can accurately reveal one’s innermost affective dispositions. In each study, we found that expressive ratings of neutral facial displays predicted self-reported positive/negative dispositional affect, but only for elderly women, and only for positive affect. These ﬁndings meaningfully replicate and extend earlier work examining age-related emotion cues in the face of elderly women (Malatesta et al., 1987a). We discuss these ﬁndings in light of evidence that women are expected to, and do, smile more than men, and that the quality of their smiles predicts their life satisfaction. Although ratings of old male faces did not signiﬁcantly predict self-reported affective dispositions, the trend was similar to that found for old female faces. A plausible explanation for this gender difference is that in the process of attenuating emotional expressions over their lifetimes, old men reveal less evidence of their total emotional experiences in their faces than do old women.},
	journaltitle = {Frontiers in Psychology},
	author = {Adams, Reginald B. and Garrido, Carlos O. and Albohn, Daniel N. and Hess, Ursula and Kleck, Robert E.},
	urldate = {2018-12-19},
	date = {2016-06-30},
	langid = {english}
}

@article{wagenmakers_registered_2016,
	title = {Registered Replication Report: Strack, Martin, \& Stepper (1988)},
	volume = {11},
	issn = {1745-6916, 1745-6924},
	url = {http://journals.sagepub.com/doi/10.1177/1745691616674458},
	doi = {10.1177/1745691616674458},
	shorttitle = {Registered Replication Report},
	abstract = {According to the facial feedback hypothesis, people’s affective responses can be influenced by their own facial expression (e.g., smiling, pouting), even when their expression did not result from their emotional experiences. For example, Strack, Martin, and Stepper (1988) instructed participants to rate the funniness of cartoons using a pen that they held in their mouth. In line with the facial feedback hypothesis, when participants held the pen with their teeth (inducing a “smile”), they rated the cartoons as funnier than when they held the pen with their lips (inducing a “pout”). This seminal study of the facial feedback hypothesis has not been replicated directly. This Registered Replication Report describes the results of 17 independent direct replications of Study 1 from Strack et al. (1988), all of which followed the same vetted protocol. A meta-analysis of these studies examined the difference in funniness ratings between the “smile” and “pout” conditions. The original Strack et al. (1988) study reported a rating difference of 0.82 units on a 10-point Likert scale. Our meta-analysis revealed a rating difference of 0.03 units with a 95\% confidence interval ranging from −0.11 to 0.16.},
	pages = {917--928},
	number = {6},
	journaltitle = {Perspectives on Psychological Science},
	author = {Wagenmakers, E.-J. and Beek, T. and Dijkhoff, L. and Gronau, Q. F. and Acosta, A. and Adams, R. B. and Albohn, Daniel N. and Allard, E. S. and Benning, S. D. and Blouin-Hudon, E.-M. and Bulnes, L. C. and Caldwell, T. L. and Calin-Jageman, R. J. and Capaldi, C. A. and Carfagno, N. S. and Chasten, K. T. and Cleeremans, A. and Connell, L. and {DeCicco}, J. M. and Dijkstra, K. and Fischer, A. H. and Foroni, F. and Hess, U. and Holmes, K. J. and Jones, J. L. H. and Klein, O. and Koch, C. and Korb, S. and Lewinski, P. and Liao, J. D. and Lund, S. and Lupianez, J. and Lynott, D. and Nance, C. N. and Oosterwijk, S. and Ozdoğru, A. A. and Pacheco-Unguetti, A. P. and Pearson, B. and Powis, C. and Riding, S. and Roberts, T.-A. and Rumiati, R. I. and Senden, M. and Shea-Shumsky, N. B. and Sobocko, K. and Soto, J. A. and Steiner, T. G. and Talarico, J. M. and van Allen, Z. M. and Vandekerckhove, M. and Wainwright, B. and Wayand, J. F. and Zeelenberg, R. and Zetzer, E. E. and Zwaan, R. A.},
	urldate = {2018-12-19},
	date = {2016-11},
	langid = {english}
}

@article{adams_social_2017,
	title = {Social Vision: Applying a Social-Functional Approach to Face and Expression Perception},
	volume = {26},
	issn = {0963-7214, 1467-8721},
	url = {http://journals.sagepub.com/doi/10.1177/0963721417706392},
	doi = {10.1177/0963721417706392},
	shorttitle = {Social Vision},
	abstract = {A social-functional approach to face processing comes with a number of assumptions. First, given that humans possess limited cognitive resources, it assumes that we naturally allocate attention to processing and integrating the most adaptively relevant social cues. Second, from these cues, we make behavioral forecasts about others in order to respond in an efficient and adaptive manner. This assumption aligns with broader ecological accounts of vision that highlight a direct action-perception link, even for nonsocial vision. Third, humans are naturally predisposed to process faces in this functionally adaptive manner. This latter contention is implied by our attraction to dynamic aspects of the face, including looking behavior and facial expressions, from which we tend to overgeneralize inferences, even when forming impressions of stable traits. The functional approach helps to address how and why observers are able to integrate functionally related compound social cues in a manner that is ecologically relevant and thus adaptive.},
	pages = {243--248},
	number = {3},
	journaltitle = {Current Directions in Psychological Science},
	author = {Adams, Reginald B. and Albohn, Daniel N. and Kveraga, Kestutis},
	urldate = {2018-12-19},
	date = {2017-06},
	langid = {english}
}

@incollection{zeigler-hill_automaticity_2018,
	location = {Cham},
	title = {Automaticity},
	isbn = {978-3-319-28099-8},
	url = {http://link.springer.com/10.1007/978-3-319-28099-8_1781-1},
	pages = {1--4},
	booktitle = {Encyclopedia of Personality and Individual Differences},
	publisher = {Springer International Publishing},
	author = {Garrido, Carlos O. and Albohn, Daniel N.},
	editor = {Zeigler-Hill, Virgil and Shackelford, Todd K.},
	urldate = {2018-12-19},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-319-28099-8_1781-1}
}

@article{freudenberg_emotional_2019,
	title = {Emotional stereotypes on trial: Implicit emotion associations for young and old adults.},
	issn = {1931-1516, 1528-3542},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/emo0000626},
	doi = {10.1037/emo0000626},
	shorttitle = {Emotional stereotypes on trial},
	abstract = {Individuals use naïve emotion theories, including stereotypical information on the emotional disposition of an interaction partner, to form social impressions. In view of an aging population in Western societies, beliefs on emotion and age become more and more relevant. Across 10 studies, we thus present findings on how individuals associate specific affective states with young and old adults using the emotion implicit association test. The results of the studies are summarized in 2 separate mini meta-analyses. Participants implicitly associated young adult individuals with positive emotions, that is, happiness and serenity, respectively, and old adult individuals with negative emotions, that is, sadness and anger, respectively (Mini Meta-Analysis 1). Within negative emotions, participants preferentially associated young adult individuals with sadness and old adult individuals with anger (Mini Meta-Analysis 2). Even though young and old adults are stereotypically associated with specific emotions, contextual factors influence which age-emotion stereotype is salient in a given context.},
	journaltitle = {Emotion},
	shortjournal = {Emotion},
	author = {Freudenberg, Maxi and Albohn, Daniel N. and Kleck, Robert E. and Adams, Reginald B. and Hess, Ursula},
	urldate = {2019-12-03},
	date = {2019-07-01},
	langid = {english}
}

@incollection{hess_perceiving_2019,
	location = {Cham},
	title = {Perceiving Emotion in the “Neutral” Face: A Powerful Mechanism of Person Perception},
	isbn = {978-3-030-32967-9 978-3-030-32968-6},
	url = {http://link.springer.com/10.1007/978-3-030-32968-6_3},
	shorttitle = {Perceiving Emotion in the “Neutral” Face},
	pages = {25--47},
	booktitle = {The Social Nature of Emotion Expression},
	publisher = {Springer International Publishing},
	author = {Albohn, Daniel N. and Brandenburg, Joseph C. and Adams, Reginald B.},
	editor = {Hess, Ursula and Hareli, Shlomo},
	urldate = {2019-12-17},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-32968-6_3}
}

@article{kveraga_spatial_2019,
	title = {Spatial and feature-based attention to expressive faces},
	volume = {237},
	issn = {0014-4819, 1432-1106},
	url = {http://link.springer.com/10.1007/s00221-019-05472-8},
	doi = {10.1007/s00221-019-05472-8},
	abstract = {Facial emotion is an important cue for deciding whether an individual is potentially helpful or harmful. However, facial expressions are inherently ambiguous and observers typically employ other cues to categorize emotion expressed on the face, such as race, sex, and context. Here, we explored the effect of increasing or reducing different types of uncertainty associated with a facial expression that is to be categorized. On each trial, observers responded according to the emotion and location of a peripherally presented face stimulus and were provided with either: (1) no information about the upcoming face; (2) its location; (3) its expressed emotion; or (4) both its location and emotion. While cueing emotion or location resulted in faster response times than cueing unpredictive information, cueing face emotion alone resulted in faster responses than cueing face location alone. Moreover, cueing both stimulus location and emotion resulted in a superadditive reduction of response times compared with cueing location or emotion alone, suggesting that feature-based attention to emotion and spatially selective attention interact to facilitate perception of face stimuli. While categorization of facial expressions was significantly affected by stable identity cues (sex and race) in the face, we found that these interactions were eliminated when uncertainty about facial expression, but not spatial uncertainty about stimulus location, was reduced by predictive cueing. This demonstrates that feature-based attention to facial expression greatly attenuates the need to rely on stable identity cues to interpret facial emotion.},
	pages = {967--975},
	number = {4},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Kveraga, Kestutis and De Vito, David and Cushing, Cody and Im, Hee Yeon and Albohn, Daniel N. and Adams, Reginald B.},
	urldate = {2020-03-05},
	date = {2019-04},
	langid = {english}
}

@article{albohn_everyday_2020,
	title = {Everyday Beliefs About Emotion Perceptually Derived From Neutral Facial Appearance},
	volume = {11},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2020.00264/full},
	doi = {10.3389/fpsyg.2020.00264},
	abstract = {The evolution of the human brain and visual system is widely believed to have been shaped by the need to process and make sense out of expressive information, particularly via the face. We are so attuned to expressive information in the face that it informs even stable trait inferences (e.g., Knutson, 1996) through a process we refer to here as the face-speciﬁc fundamental attribution error (Albohn et al., 2019). We even derive highly consistent beliefs about the emotional lives of others based on emotion-resembling facial appearance (e.g., low versus high brows, big versus small eyes, etc.) in faces we know are completely devoid of overt expression (i.e., emotion overgeneralization effect: see Zebrowitz et al., 2010). The present studies extend these insights to better understand lay beliefs about older and younger adults’ emotion dispositions and their impact on behavioral outcomes. In Study 1, we found that older versus younger faces objectively have more negative emotion-resembling cues in the face (using computer vision), and that raters likewise attribute more negative emotional dispositions to older versus younger adults based just on neutral facial appearance (see too Adams et al., 2016). In Study 2, we found that people appear to encode these negative emotional appearance cues in memory more so for older than younger adult faces. Finally, in Study 3 we exam downstream behavioral consequences of these negative attributions, showing that observers’ avoidance of older versus younger faces is mediated by emotion-resembling facial appearance.},
	pages = {264},
	journaltitle = {Frontiers in Psychology},
	shortjournal = {Front. Psychol.},
	author = {Albohn, Daniel N. and Adams, Reginald B.},
	urldate = {2020-03-17},
	date = {2020-02-28},
	langid = {english}
}

@article{albohn_emotion_2020,
	title = {Emotion Residue in Neutral Faces: Implications for Impression Formation},
	issn = {1948-5506, 1948-5514},
	url = {http://journals.sagepub.com/doi/10.1177/1948550620923229},
	doi = {10.1177/1948550620923229},
	shorttitle = {Emotion Residue in Neutral Faces},
	abstract = {Despite the prevalent use of neutral faces in expression research, the term neutral still remains ill-defined and understudied. A general assumption is that one’s overt attempt to pose a nonexpressive face results in a neutral display, one devoid of any expressive information. Ample research has demonstrated that nonexpressive faces do convey meaning, however, through emotion-resembling appearance. Here, we examined whether prior expressive information lingers on a face, in the form of emotion residue, and whether despite overt attempts to display a neutral face, these subtle emotion cues influence trait impressions. Across three studies, we found that explicit attempts at posing neutral displays retained emotion residue from a prior expression. This residue in turn significantly impacted the impressions formed of these otherwise “neutral” displays. We discuss implications of this work for better understanding how accurate impressions are derived from the so-called neutral faces and underscore theoretical and methodological considerations for future research.},
	pages = {194855062092322},
	journaltitle = {Social Psychological and Personality Science},
	shortjournal = {Social Psychological and Personality Science},
	author = {Albohn, Daniel N. and Adams, Reginald B.},
	urldate = {2020-09-14},
	date = {2020-06-26},
	langid = {english}
}

@incollection{adams_differential_2019,
	title = {Differential magnocellular versus parvocellular pathway contributions to the combinatorial processing of facial threat},
	volume = {247},
	isbn = {978-0-444-64252-3},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0079612319300366},
	abstract = {Recently, speed of presentation of facially expressive stimuli was found to influence the processing of compound threat cues (e.g., anger/fear/gaze). For instance, greater amygdala responses were found to clear (e.g., direct gaze anger/averted gaze fear) versus ambiguous (averted gaze anger/direct gaze fear) combinations of threat cues when rapidly presented (33 and 300 ms), but greater to ambiguous versus clear threat cues when presented for more sustained durations (1, 1.5, and 2 s). A working hypothesis was put forth (Adams et al., 2012) that these effects were due to differential magnocellular versus parvocellular pathways contributions to the rapid versus sustained processing of threat, respectively. To test this possibility directly here, we restricted visual stream processing in the {fMRI} environment using facially expressive stimuli specifically designed to bias visual input exclusively to the magnocellular versus parvocellular pathways. We found that for magnocellular-biased stimuli, activations were predominantly greater to clear versus ambiguous threat-gaze pairs (on par with that previously found for rapid presentations of threat cues), whereas activations to ambiguous versus clear threat-gaze pairs were greater for parvocellular-biased stimuli (on par with that previously found for sustained presentations). We couch these findings in an adaptive dual process account of threat perception and highlight implications for other dual process models within psychology.},
	pages = {71--87},
	booktitle = {Progress in Brain Research},
	publisher = {Elsevier},
	author = {Adams, Reginald B. and Im, Hee Yeon and Cushing, Cody and Boshyan, Jasmine and Ward, Noreen and Albohn, Daniel N. and Kveraga, Kestutis},
	urldate = {2020-09-24},
	date = {2019},
	langid = {english},
	doi = {10.1016/bs.pbr.2019.03.006}
}

@article{cho_culture_2018,
	title = {Culture Moderates the Relationship Between Emotional Fit and Collective Aspects of Well-Being},
	volume = {9},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2018.01509/full},
	doi = {10.3389/fpsyg.2018.01509},
	pages = {1509},
	journaltitle = {Frontiers in Psychology},
	shortjournal = {Front. Psychol.},
	author = {Cho, Sinhae and Doren, Natalia Van and Minnick, Mark R. and Albohn, Daniel N. and Adams, Reginald B. and Soto, José A.},
	urldate = {2020-09-24},
	date = {2018-08-24},
	langid = {english}
}

@article{im_cross-cultural_2017,
	title = {Cross-cultural and hemispheric laterality effects on the ensemble coding of emotion in facial crowds},
	volume = {5},
	issn = {2193-8652, 2193-8660},
	url = {http://link.springer.com/10.1007/s40167-017-0054-y},
	doi = {10.1007/s40167-017-0054-y},
	pages = {125--152},
	number = {2},
	journaltitle = {Culture and Brain},
	shortjournal = {Cult. Brain},
	author = {Im, Hee Yeon and Chong, Sang Chul and Sun, Jisoo and Steiner, Troy G. and Albohn, Daniel N. and Adams, Reginald B. and Kveraga, Kestutis},
	urldate = {2020-09-24},
	date = {2017-10},
	langid = {english}
}

@article{rush_effects_2017,
	title = {The Effects of a Mindfulness and Biofeedback Program on the On- and Off-Task Behaviors of Students with Emotional Behavioral Disorders},
	volume = {21},
	issn = {2159-2020, 2161-1505},
	url = {http://link.springer.com/10.1007/s40688-017-0140-3},
	doi = {10.1007/s40688-017-0140-3},
	pages = {347--357},
	number = {4},
	journaltitle = {Contemporary School Psychology},
	shortjournal = {Contemp School Psychol},
	author = {Rush, Karena S. and Golden, Maria E. and Mortenson, Bruce P. and Albohn, Daniel N. and Horger, Melissa},
	urldate = {2020-09-24},
	date = {2017-12},
	langid = {english}
}

@incollection{adams_social_2017-1,
	edition = {2},
	title = {A Social Vision Account of Facial Expression Perception},
	url = {https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780190613501.001.0001/acprof-9780190613501},
	pages = {315--332},
	booktitle = {The Science of Facial Expressions},
	publisher = {Oxford University Press},
	author = {Adams, R. B. and {Albohn, D.N.} and {Kveraga, K}},
	editor = {Fernandez-Dols, Jose-Miguel and Russell, James A.},
	date = {2017}
}

@article{matteucci_exercise_2012,
	title = {Exercise Behavior Among College Students and Sex Differences in a Health-Promotive Intervention},
	abstract = {This study examined the effectiveness of a university-based Life Fitness course on college students' health behavior in terms ofthe number of hours students spent doing various types of exercise-related activities (moderate activities, hard activities, and very hard activities) before and after the course. Participants were asked to complete a series of questions regarding daily activity levels and habits both before and after the completion ofthe course. Results revealed significant increases in the mean number of hours spent on each type of exercise-related activity. Specifically, for moderate activities, there were significant main effects for time, F\{1, 187) = 6.70, p = .01, n 2 = .04, and sex, F\{1, 187) = 18.80, p {\textless} .001, ri {\textasciicircum} = .09, with increases in these activities across time and men reporting higher mean levels of this activity compared to women. For hard activities, there was a significant time xsex interaction, F\{1, 112) = 5.90, p = .03, r) {\textasciicircum} = .04, indicating more dramatic increases for men during this period. For very hard activities, there was a significant main effect for sex, i{\textasciicircum}(l, 112) = 11.40, /? {\textless} .001, r) {\textasciicircum} = .09, indicating that men reported higher mean levels ofthese activities relative to women. Findings yield important implications for future research on the relationship between health-promotive intervention and students' health-related behaviors and the establishment of healthy attitudes and behaviors that persist into adulthood.},
	pages = {9},
	url = {https://www.psichi.org/page/174JNWinter2012#.X25GNdZ7l24},
	journaltitle = {Psi Chi Journal of Reserach},
	author = {Matteucci, Alyssa J. and Albohn, Daniel N. and Stoppa, Tara M. and Mercier, Wendy},
	date = {2012},
	doi  = {10.24839/2164-8204.JN17.4.163},
	langid = {english}
}